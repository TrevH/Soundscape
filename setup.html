<div class="col-xl-3 col-lg-3 col-md-3 col-sm-12 left_content ">
    <h3 class="abstract">Setup</h3>
    <p class="abstract_content border font-italic font-weight-light  border-left-0 border-top-0 border-bottom-0">In a nutshell, Soundscape maps readings from sensors on large panels made of stretch material to controls within Ableton and then uses the sound generated by Ableton to make visuals responsive to the music. There is a combination of technologies used to provide this functionality.  This page provides some detail on the technologies used and how it all connects together.</p>
</div>

<div class="col-xl-9 col-lg-9 col-md-9 col-sm-12 mid_content">
    <div class="right_border_mid_content">
        <h4>Floor and Screens</h4>
        <p>The structure if Soundscape is fully portable and working with the constraints of size and mobility we decided to make it as modular as possible. The space needed is approximately 3m x 3m which allows room for the structure, the projectors and mirrors, the operations and sound desk while being able to manoeuvre around the structure.</p>

        <p>The four floor separate panels that resembles four sails are clipped together to stop movement of the panels. The floor area in the front of the screens is greater to allow a space for the performers to stand on as well as providing more stability for the whole structure. Yellow duct tape has been placed around the outer edge of the panels to abide with workplace health and safety concerns of having a raised edge to the floor.</p>

        <p>The four screens fit into a groove on each their specific floor panel. This groove holds the screen in place in an upright position. It important to be careful with these panels as they house the wiring that connects the flex sensors to the Arduinos. To keep these screens, stable there is a Perspex stand at the rear of the screen and two latches at the bottom of the front of the screen. To provide added stability there is a plate that fits over pegs at the top of each screen.</p>

        <div class="row">
            <div class="col-lg-6">
                <figure class="figure">
                    <img src="assets/setup2.JPG" class="figure-img img-fluid" alt="Arduino megas and their protective case">
                    <p class=" text-right text-muted">Arduino megas and their protective case</p>
                </figure>
            </div>
            <div class="col-lg-6">
                    <figure class="figure">
                        <img src="assets/setup3.JPG" class="figure-img img-fluid" alt="Working in Unity to manage the projection">
                        <p class=" text-right text-muted">Working in Unity to manage the projection</p>
                    </figure>
                </div>
        </div>

        <h4>The Arduinos</h4>
        <p>The major component that allows the conversations between the sensors and the computer is given a considerable priority and hence, the four Arduino Megas are housed in a purposed built box that allows the ribbon wiring, running from the screens, to be connected via a parallel plug to breadboard and Arduino. Each individual Arduino gains power by being plugged into a powered USB hub that is connected to the computers.</p>

        <h4>Projectors</h4>
        <p>The visuals are projected onto the screens by two Epson EH-TW5600 LCD High Definition 3D Home theatre projectors. These are placed at specifically marked positions at the rear of the screens to allow each unit to provide projection onto two screens. A convex safety mirror is positioned in front of the projectors to equally project images onto each screen.</p>

        <h4>Ableton & max 4 Live</h4>
        <p>On opening up Ableton it is important to open up both Ableton Live 9 and MAX 4 Live. Ableton manipulates the composition and MAX provides the mapping between Ableton and the Unity.  Check that MAX 4 Live is open by clicking anywhere in the first midi channel. The patching map will show in the mixing panel of the interface. It is important you have the correct Live set (with MAX 4 Live) or the computers will not communicate with each other.</p>

        <p>The music can be manipulated manually using the controls on the interface but the project is set up to start when a performer touches any screen.</p>

        <h4>Unity</h4>
        <p>When you open the project in Unity, it is important to check the Arduinos are running and reading inputs from the sensors – this check will help trouble shoot any problems and save time later.</p>

        <p>Click PLAY – this will bring up two displays for the LEFT and RIGHT sides of the screens.</p>

        <p>The displays on the monitors need to be moved to align the touch icons (that provide feedback to the performers) with the sensors on the screens. Sometimes this could mean readjusting the displays as well as the mirrors if there has been a considerable amount of moving of the equipment.</p>

        <p>Press the UP arrow to calibrate the sensor readings. These starting values will vary each time and it is important to level these readings to provide a similar experience in performance each time.</p>

        <p>When the performer is ready to interact with the surface Press SPACE BAR. This prevents any accidental starting of the music - this was important with the iPad performance but may not be as important with future performance.</p>

        <figure class="figure">
            <img src="assets/setup1.png" class="figure-img img-fluid" alt="Connecting the elements of Soundscape">
            <p class=" text-right text-muted">How the elements of Soundscape connect together</p>
        </figure>

        <h4>Connecting it all together</h4>
        <p>Each screen has eight flex sensors that when pressed send analogue readings to the Arduinos. There are four panels (each with eight sensors) so it was essential to use Arduino Megas – one for each.</p>

        <p>The Arduinos bundle the readings and send them in a regular pattern via serial communication to Unity on one computer. Communicating via an Ethernet, an OSC (Open Sound Control) is sent to another computer running MAX 4 Live.</p>

        <p>The mapping in MAX directs the specific signal from each sensor and controls the effects of each sound source created in Ableton Live. The audio signal created by Ableton (music) are sent back to Unity as an audio stream – connecting from the headphone output, of one computer, to the line-in of the other computer.</p>

        <p>The Audio signal is then sent through unity to the sound system to the speakers to give sound.</p>  
        
        <p>It is also used by Unity to create visuals.  The spectra of the audio is broken into frequency bands and changes in these frequencies are used to control the particle systems that make up the visuals.  A different camera is focused on each particle system to allow for each panel to have a different display.  The visuals from two cameras are then combined into one display for each panel.  These are directed to two projectors allowing for the visuals for two panels to be displayed onto a single panel without (much) overlap between the displays.</p>
    </div>
</div>


